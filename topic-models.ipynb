{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assured-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tabula import read_pdf\n",
    "from tika import parser \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc\n",
    "import gensim\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim import models\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "nlp.max_length = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "danish-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "files1 = glob.glob(\"/Users/test/Desktop/topic modelsss/new/Session 72 - 2017/*.PDF\")\n",
    "files2 = glob.glob(\"/Users/test/Desktop/topic modelsss/new/Session 72 - 2017/*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affiliated-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for file in files1:\n",
    "    raw = parser.from_file(file)\n",
    "    doc = raw['content'].split()\n",
    "    docs.append(doc)\n",
    "\n",
    "for file in files2:\n",
    "    raw = parser.from_file(file)\n",
    "    doc = raw['content'].split()\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electrical-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphanumeric(word):\n",
    "    return re.sub(r'\\W+', '', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrative-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_non_ascii(s):\n",
    "    return any(ord(i) > 127 for i in s)\n",
    "\n",
    "def is_valid_word(word, stop_words=STOP_WORDS):\n",
    "    \"\"\"Checks if the word is valid for training or inference\"\"\"\n",
    "\n",
    "    if stop_words and word in stop_words:\n",
    "        return False\n",
    "\n",
    "    if contains_non_ascii(word):\n",
    "        return False\n",
    "\n",
    "    distinct_keys = len(''.join(set(word)))\n",
    "    if len(word) <= 2 or distinct_keys == 1:\n",
    "        return False\n",
    "\n",
    "    if word.isdigit() or word == \"0\":\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "potential-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemma(vocab_str):\n",
    "\n",
    "    for i in nlp(vocab_str):\n",
    "        return i.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "awful-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_concated = []\n",
    "for doc in docs:\n",
    "    docs_concated = docs_concated + doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ethical-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'vocab':docs_concated})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "equipped-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vocab'] = df['vocab'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regular-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vocab'] = df['vocab'].apply(alphanumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "narrative-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valid'] = df['vocab'].apply(is_valid_word)\n",
    "df = df[df['valid']==True]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "light-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['vocab'] = df['vocab'].apply(spacy_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "artistic-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = df.groupby(\"vocab\").size().reset_index(name='count').sort_values(\"count\", ascending=False).head(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fiscal-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(vocab['vocab'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "together-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_top_words(doc, vocab=vocab):\n",
    "    return [word for word in doc if word in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civilian-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_cleaned = [keep_top_words(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-latin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "quarterly-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(docs_cleaned)\n",
    "corpus = [id2word.doc2bow(text) for text in docs_cleaned]\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "lightweight-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus_tfidf, id2word=id2word,  iterations=150, alpha=0.0001, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "inside-stockholm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.001*\"lift\" + 0.001*\"corrupt\" + 0.001*\"devotion\" + 0.001*\"wait\" + 0.001*\"ignorance\" + 0.001*\"seats\" + 0.001*\"games\" + 0.001*\"die\" + 0.001*\"represented\" + 0.001*\"enemies\"\n",
      "Topic: 1 \n",
      "Words: 0.001*\"budgets\" + 0.001*\"murdered\" + 0.001*\"violated\" + 0.001*\"apartheid\" + 0.001*\"drugs\" + 0.001*\"patience\" + 0.001*\"drug\" + 0.001*\"hydrogen\" + 0.001*\"correspondent\" + 0.001*\"occupation\"\n",
      "Topic: 2 \n",
      "Words: 0.001*\"indigenous\" + 0.001*\"aspect\" + 0.001*\"formal\" + 0.001*\"lourish\" + 0.001*\"escorted\" + 0.001*\"rescue\" + 0.001*\"grand\" + 0.001*\"yesterday\" + 0.001*\"crop\" + 0.001*\"nutrition\"\n",
      "Topic: 3 \n",
      "Words: 0.001*\"environments\" + 0.001*\"fisheries\" + 0.001*\"repatriation\" + 0.001*\"escorted\" + 0.001*\"disregard\" + 0.001*\"centuries\" + 0.001*\"serves\" + 0.001*\"minorities\" + 0.001*\"committee\" + 0.001*\"reforming\"\n",
      "Topic: 4 \n",
      "Words: 0.001*\"bank\" + 0.001*\"tax\" + 0.001*\"escorted\" + 0.001*\"provinces\" + 0.001*\"apartheid\" + 0.001*\"definition\" + 0.001*\"terrorists\" + 0.001*\"victim\" + 0.001*\"electoral\" + 0.001*\"eradication\"\n",
      "Topic: 5 \n",
      "Words: 0.000*\"foster\" + 0.000*\"forgotten\" + 0.000*\"fresh\" + 0.000*\"fraternal\" + 0.000*\"found\" + 0.000*\"fuelled\" + 0.000*\"forums\" + 0.000*\"forge\" + 0.000*\"forget\" + 0.000*\"gain\"\n",
      "Topic: 6 \n",
      "Words: 0.001*\"bin\" + 0.001*\"ecosystem\" + 0.001*\"canoe\" + 0.001*\"radicalism\" + 0.001*\"escorted\" + 0.001*\"impacts\" + 0.001*\"illiteracy\" + 0.001*\"optimism\" + 0.001*\"loud\" + 0.001*\"moderation\"\n",
      "Topic: 7 \n",
      "Words: 0.001*\"owe\" + 0.001*\"exceptional\" + 0.001*\"drug\" + 0.001*\"roads\" + 0.001*\"customs\" + 0.001*\"bin\" + 0.001*\"went\" + 0.001*\"negatively\" + 0.001*\"escorted\" + 0.001*\"weapon\"\n",
      "Topic: 8 \n",
      "Words: 0.001*\"moderation\" + 0.001*\"siege\" + 0.001*\"facilitated\" + 0.001*\"drug\" + 0.001*\"allegations\" + 0.001*\"costs\" + 0.001*\"interconnected\" + 0.001*\"transportation\" + 0.001*\"landlocked\" + 0.001*\"escorted\"\n",
      "Topic: 9 \n",
      "Words: 0.001*\"escorted\" + 0.001*\"ref\" + 0.001*\"lose\" + 0.001*\"cases\" + 0.001*\"cholera\" + 0.001*\"reviews\" + 0.001*\"militias\" + 0.001*\"replaced\" + 0.001*\"coercive\" + 0.001*\"picture\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "        print('Topic: {} \\nWords: {}'.format(idx, topic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-radical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "located-singapore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-warning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-clerk",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
